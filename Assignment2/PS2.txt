1. Based on the histograms, which attribute appears to be the most useful for classifying wine, and why?
[Answer]: Alcohol appears to be the most useful for classifying wine because according the histogram of the attribute alcohol, it shows approximates normal distribution on the class attribute (i.e. quality) of bad and good (red and blue).

2. What is the accuracy - the percentage of correctly classified instances - achieved by ZeroR when you run it on the training set? Why is ZeroR a helpful baseline for interpreting the performance of other classifiers?
[Answer]: Accuracy  - the percentage of correctly classified instances - achieved by ZeroR is mentioned below:
=================================================================================
Correctly Classified Instances        1179               62.381 %      
=================================================================================               
ZeroR classifier is simply assigning each value to the most common class attribute and that is why it is giving almost least performance. This is why we can assume this classifier as baseline and examine other classifier comparing with the performance with ZeroR classifier. All other classifier performance should perform better than ZeroR.
 
3. Using a decision tree Weka learned over the training set, what is the most informative single feature for this task, and what is its influence on wine quality (i.e., what values of the feature are correlated with higher wine quality)? Does this match your answer from question 1?
[Answer]: The most informative single feature for this task is "alcohol" (according to "J48" classifier). The influence of the attribute of alcohol on wine quality is like when the alcohol amount increases then there is more chances of getting quality as good for that wine and similarly if the amount of alcohol decreases then there are more chances of considering wine as of bad quality. For example, approximately alcohol > 11 is correlated as higher wine quality whereas alcohol <= 11 is correlated as lesser wine quality.
Yes, this matches with my answer from question 1.

4.	What is 10-fold cross-validation? What is the main reason for the difference between the percentage of Correctly Classified Instances when you measured accuracy on the training set itself, versus when you ran 10-fold cross-validation over the training set? Why is cross-validation important?
[Answer]: 10-fold cross-validation is a technique to evaluate a predictive model. It actually breaks the data into 10 sets of size n/10, then it will train on 9 datasets and test on 1 dataset. This process is repeated 10 times and then take a mean accuracy. 
The 10-fold cross validation for classifier J48 is mentioned below:
=================================================================================
Correctly Classified Instances        1625               85.9788 %
=================================================================================

The accuracy on complete training set for classifier J48 is mentioned below:
=================================================================================
Correctly Classified Instances        1812               95.873  %
=================================================================================
Difference = 95.873 - 85.9788 = 9.8942
The main reason for the difference between the percentage of Correctly Classified Instances when you measured accuracy on the training set itself, versus when you ran 10-fold cross-validation over the training set is because the decision tree in the case of "10-cross validation" was created on 9/10th portions of the data and then it performed testing on 1/10th portion of the data whereas the decision tree in the other case (on the training set) was created on complete dataset.

5.	What is the "command-line" for the model you are submitting? For example, "J48 -C 0.25 -M 2". What is the reported accuracy for your model using 10-fold cross-validation?
[Answer]: command-line for my model is = "weka.classifiers.trees.RandomForest -P 100 -I 100 -num-slots 1 -K 0 -M 1.0 -V 0.001 -S 500 -B"
The reported accuracy for my model using 10-fold cross-validation is mentioned below:
=================================================================================
Correctly Classified Instances        1721               91.0582 %
=================================================================================

6.	In a few sentences, describe how you chose the model you are submitting. Be sure to mention your validation strategy and whether you tried varying any of the model parameters.
[Answer]: I have chosen random forest because I am able to achieve the highest accuracy with random forest compared to all other classifiers like J48 decision tree, k star, etc. The error rate for the random forest is also less than all other classifiers. Random forest is normalizing the over-fitting risk by averaging several decision trees.
The validation strategy I used is 10 fold cross validation. 
I have tried varying following model parameters which led to increasing the accuracy by more than approx 1%:-
a) breakTiesRandomly (Break ties randomly when several attributes look equally good): True
b) seed (The random number seed to be used): 500
 
7. Briefly explain what strategy you used to obtain the Classifiers A and B that performed well on one of the cars or wine data sets and not the other. Tell us which classifiers you chose and what their 10-fold CV accuracies were on each of the car and wine training data sets.
[Answer]: I have chosen Classifiers A and B that performed well on one of the cars or wine data sets on the basis of their attribute histograms. 
a) In the case of the car, the values for all their attribute is less compare to the wine dataset attributes. For example, the number of distinct values for car's attribute "persons" is only 3 whereas the number of distinct values for wine's attribute "residual sugar" is 238.
b) Another major difference between these data-set's attribute is their uniqueness. For example, the uniqueness for the attributes of car dataset is zero while the same is not the case with wine datasets.
c) Also, all the attribute for wine dataset is numeric in nature (except the class attribute) whereas all the attribute for car dataset is nominal. 

Classifier (A) used for wine dataset = RandomForest
Classifier (B) used for car dataset = multilayer perceptron

Please find the 10-fold CV accuracy and their accuracy difference mentioned below:-
Wine data set 10-fold CV accuracy on classifier A = 91.0582 %
Car data set 10-fold CV accuracy on classifier B = 99.2437 %
Wine data set 10-fold CV accuracy on classifier B = 84.9735 %
Car data set 10-fold CV accuracy on classifier A = 93.1933 %

Difference => 91.0582 + 99.2437 - 84.9735 - 93.1933 = 12.1351

8. Consider the following four functions fi each defined over a single attribute x. For each data set, one of the following learners performs best in terms of leave-one-out cross-validation: one-nearest-neighbor, three-nearest-neighbor, linear regression, and polynomial regression. For each function, the state which of the four learning methods is best in terms of leave-one-out cross-validation, and in 1-2 sentences say convincingly why this is the case. You don't have to explicitly compute the LOOCV accuracy or sum squared error in each case, although in some cases doing the computation might be a good route to a convincing explanation for why your chosen method is best.
[Answer]: 
f1 = one-nearest-neighbor
[Explanation]: It is very clear from the f(x) data that the one nearest-neighbor is best suits for this function. For example, if we draw this on axis, 
          +  +    -  -    + 
		--|--|----|--|----|--
		  1  2    4  5    7

you can see below observations 
for x=1 the 1-nearest nearest-neighbor is f(2), which is + => correct,
for x=2 the 1-nearest nearest-neighbor is f(1), which is + => correct,
for x=4 the 1-nearest nearest-neighbor is f(5), which is - => correct,
for x=5 the 1-nearest nearest-neighbor is f(4), which is - => correct,
for x=7 the 1-nearest nearest-neighbor is f(5), which is - => incorrect,  
So, we got 4/5 correct which is 80% accuracy 

f2 = linear regression
[Explanation] :  All the x data for this function is linearly related to f(x). For example, for x=1, f(x)=3, for x=2, f(x)=6.5, and similarly for x=7, f(x)=21. It is deducing the linear regression equation of something like f(x) = 3x ± 0.5

f3 = polynomial regression
[Explanation] : All the x data for this function is polynomially related to f(x). For example, for x=1, f(x)=2, for x=2, f(x)=5 and similarly for x=7, f(x)=49.
It is deducing the quadratic (polynomial) equation of something like f(x) = x^2 ± 1

f4 = three-nearest-neighbor
[Explanation] : It is very clear from the f(x) data that the three nearest-neighbor is best suits for this function. For example if we draw this on axis, 
          +  +    +  -    + 
		--|--|----|--|----|--
		  1  2    4  5    7

you can see below observations 
for x=1 the 3-nearest nearest-neighbor is f(2), f(4), f(5), which results majority of + => correct,
for x=2 the 3-nearest nearest-neighbor is f(1), f(4), f(5), which results majority of + => correct,
for x=4 the 3-nearest nearest-neighbor is f(1)/f(7), f(2), f(5), which results majority of + => correct,
for x=5 the 3-nearest nearest-neighbor is f(2), f(4), f(7), which results majority of + => incorrect,
for x=7 the 3-nearest nearest-neighbor is f(2), f(4), f(5), which results majority of + => correct,
So, we got 4/5 correct which is 80% accuracy 